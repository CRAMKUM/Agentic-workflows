{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to Lab 3 for Week 1 Day 4\n",
    "\n",
    "Today we're going to build something with immediate value!\n",
    "\n",
    "In the folder `me` I've put a single file `linkedin.pdf` - it's a PDF download of my LinkedIn profile.\n",
    "\n",
    "Please replace it with yours!\n",
    "\n",
    "I've also made a file called `summary.txt`\n",
    "\n",
    "We're not going to use Tools just yet - we're going to add the tool tomorrow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Looking up packages</h2>\n",
    "            <span style=\"color:#00bfff;\">In this lab, we're going to use the wonderful Gradio package for building quick UIs, \n",
    "            and we're also going to use the popular PyPDF PDF reader. You can get guides to these packages by asking \n",
    "            ChatGPT or Claude, and you find all open-source packages on the repository <a href=\"https://pypi.org\">https://pypi.org</a>.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't know what any of these packages do - you can always ask ChatGPT for a guide!\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"me/profile.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n",
      "Contact\n",
      "email4chai@gmail.com\n",
      "www.linkedin.com/in/chaithanya-\n",
      "ramkumar-95ab87155 (LinkedIn)\n",
      "Top Skills\n",
      "Retrieval-Augmented Generation\n",
      "(RAG)\n",
      "Llm engineering\n",
      "RLHF\n",
      "Certifications\n",
      "Deep Learning A-Z : Hands on\n",
      "Artificial Neural Networks\n",
      "Chaithanya Ramkumar\n",
      "Digital AI prototype development | AI/ML Architect\n",
      "Bengaluru, Karnataka, India\n",
      "Summary\n",
      "I'm working on scoping business needs from various stakeholders\n",
      "and architecting AI based solutions. My job involves rapid\n",
      "prototyping with cutting edge AI models, architectures to deliver AI\n",
      "based prototypes and products which bring savings and efficiency.\n",
      "I work hands on in certain critical bricks for the product while also\n",
      "delegating other bricks to a team. I finally integrate all the bricks to\n",
      "make a complete end to end AI solution. \n",
      "I also lead smaller sized teams to develop various features in the\n",
      "prototypes and products. \n",
      "I also have a rich background in automotive, aerospace and thermal\n",
      "management domains.\n",
      "Experience\n",
      "Airbus\n",
      "Data Scientist\n",
      "July 2025 - Present (6 months)\n",
      "Bengaluru, Karnataka, India\n",
      "Fine tuning LLMS, RAG, RLHF, VLMs\n",
      "Volvo Group\n",
      "3 years 1 month\n",
      "Professional Data and Simulation Engineer\n",
      "January 2024 - August 2025 (1 year 8 months)\n",
      "Bengaluru, Karnataka, India\n",
      "Senior 1 D Simulation Analyst\n",
      "August 2022 - January 2024 (1 year 6 months)\n",
      "Bengaluru, Karnataka, India\n",
      "Mercedes-Benz Research and Development India\n",
      "Senior Engineer\n",
      "April 2020 - September 2022 (2 years 6 months)\n",
      "Bengaluru, Karnataka\n",
      "  Page 1 of 3   \n",
      "Performing system level Engine Thermal Management using 1D CFD tools\n",
      "such as GT SUITE for various drive cycles. \n",
      "Detroit Engineered Products\n",
      "Thermal CFD Engineer\n",
      "February 2019 - March 2020 (1 year 2 months)\n",
      "Bengaluru, Karnataka, India\n",
      "Performing 1D system level engine thermal management\n",
      "General Motors Technical Center India\n",
      "CFD System Engineer\n",
      "July 2015 - February 2019 (3 years 8 months)\n",
      "Bangalore\n",
      "Skills:\n",
      "• Strong technical skills in Amesim, GT power, Matlab.\n",
      "• Underwent training in Star CCM+ and Simulink\n",
      "• Completed both DFSS(Design for Six Sigma) Green belt and Black belt\n",
      "certification.\n",
      "• Have sufficient knowledge of Pure electric, Hybrid, Fuel cell vehicles. \n",
      "Work experience highlights\n",
      "Regular role-\n",
      "• Completed 6 projects on Camphaser dynamic analysis, 3 projects on\n",
      "Lubrication system analysis, 5 \n",
      "on Fuel system analysis, 3 on Vane pump modelling using Amesim and\n",
      "delivered results on time \n",
      "with First time quality.\n",
      "• Completed 3 projects on Crankcase breathing analysis and 2 on cooling\n",
      "system analysis using GT \n",
      "power.\n",
      "• Performed flow vs Pressure drop analysis on complex restrictions in the\n",
      "lubrication system using \n",
      "CCM+.\n",
      "Quality/Efficiency/Design improvement role-\n",
      "• Developed crankcase breathing analysis procedure by visiting test setups in\n",
      "GM tech center at \n",
      "Pontiac, collecting data from the suppliers and benchmarking the analysis\n",
      "results to match the \n",
      "  Page 2 of 3   \n",
      "test.\n",
      "• Developed cam phaser dynamic analysis procedure by coupling with lube\n",
      "circuit and accurately \n",
      "predicting the OCV feed pressure and the camphaser response rates.\n",
      "• Automated fuel system analysis procedure by using Matlab scripts and\n",
      "coupled it with AMESim \n",
      "which saved 4 to 5 hours of post processing time.\n",
      "• Provided design modifications to Lubrication system Design Release\n",
      "Engineer(DRE) and matched \n",
      "the desired pressure at the gallery.\n",
      "Innovative/mentoring role- \n",
      "• Published two defensive publications on the topic –‘Obtaining optimum\n",
      "camphaser response by \n",
      "dynamically changing the bias spring preload angle’. \n",
      "• Coached and mentored a trainee engineer on Crankcase breathing, Fuel\n",
      "system, Lube system and \n",
      "Camphaser analysis procedures using Matlab and GT power.\n",
      "Travel experience\n",
      "• Was sent to GM tech center in Detroit to support Camphaser and Crankcase \n",
      "breathing analysis procedure improvement work.\n",
      "Education\n",
      "Indian Institute of Technology, Madras\n",
      "Master of Technology - MTech, fluid · (2013 - 2015)\n",
      "  Page 3 of 3\n"
     ]
    }
   ],
   "source": [
    "print(linkedin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"me/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm working on scoping business needs from various stakeholders\\nand architecting AI based solutions. My job involves rapid\\nprototyping with cutting edge AI models, architectures to deliver AI\\nbased prototypes and products which bring savings and efficiency.\\nI work hands on in certain critical bricks for the product while also\\ndelegating other bricks to a team. I finally integrate all the bricks to\\nmake a complete end to end AI solution. \\nI also lead smaller sized teams to develop various features in the\\nprototypes and products. \\nI also have a rich background in automotive, aerospace and thermal\\nmanagement domains.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Chaithanya Ramkumar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer, say so.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are acting as Chaithanya Ramkumar. You are answering questions on Chaithanya Ramkumar's website, particularly questions related to Chaithanya Ramkumar's career, background, skills and experience. Your responsibility is to represent Chaithanya Ramkumar for interactions on the website as faithfully as possible. You are given a summary of Chaithanya Ramkumar's background and LinkedIn profile which you can use to answer questions. Be professional and engaging, as if talking to a potential client or future employer who came across the website. If you don't know the answer, say so.\\n\\n## Summary:\\nI'm working on scoping business needs from various stakeholders\\nand architecting AI based solutions. My job involves rapid\\nprototyping with cutting edge AI models, architectures to deliver AI\\nbased prototypes and products which bring savings and efficiency.\\nI work hands on in certain critical bricks for the product while also\\ndelegating other bricks to a team. I finally integrate all the bricks to\\nmake a complete end to end AI solution. \\nI also lead smaller sized teams to develop various features in the\\nprototypes and products. \\nI also have a rich background in automotive, aerospace and thermal\\nmanagement domains.\\n\\n## LinkedIn Profile:\\n\\xa0 \\xa0\\nContact\\nemail4chai@gmail.com\\nwww.linkedin.com/in/chaithanya-\\nramkumar-95ab87155 (LinkedIn)\\nTop Skills\\nRetrieval-Augmented Generation\\n(RAG)\\nLlm engineering\\nRLHF\\nCertifications\\nDeep Learning A-Z : Hands on\\nArtificial Neural Networks\\nChaithanya Ramkumar\\nDigital AI prototype development | AI/ML Architect\\nBengaluru, Karnataka, India\\nSummary\\nI'm working on scoping business needs from various stakeholders\\nand architecting AI based solutions. My job involves rapid\\nprototyping with cutting edge AI models, architectures to deliver AI\\nbased prototypes and products which bring savings and efficiency.\\nI work hands on in certain critical bricks for the product while also\\ndelegating other bricks to a team. I finally integrate all the bricks to\\nmake a complete end to end AI solution. \\nI also lead smaller sized teams to develop various features in the\\nprototypes and products. \\nI also have a rich background in automotive, aerospace and thermal\\nmanagement domains.\\nExperience\\nAirbus\\nData Scientist\\nJuly 2025\\xa0-\\xa0Present\\xa0(6 months)\\nBengaluru, Karnataka, India\\nFine tuning LLMS, RAG, RLHF, VLMs\\nVolvo Group\\n3 years 1 month\\nProfessional Data and Simulation Engineer\\nJanuary 2024\\xa0-\\xa0August 2025\\xa0(1 year 8 months)\\nBengaluru, Karnataka, India\\nSenior 1 D Simulation Analyst\\nAugust 2022\\xa0-\\xa0January 2024\\xa0(1 year 6 months)\\nBengaluru, Karnataka, India\\nMercedes-Benz Research and Development India\\nSenior Engineer\\nApril 2020\\xa0-\\xa0September 2022\\xa0(2 years 6 months)\\nBengaluru, Karnataka\\n\\xa0 Page 1 of 3\\xa0 \\xa0\\nPerforming system level Engine Thermal Management using 1D CFD tools\\nsuch as GT SUITE for various drive cycles. \\nDetroit Engineered Products\\nThermal CFD Engineer\\nFebruary 2019\\xa0-\\xa0March 2020\\xa0(1 year 2 months)\\nBengaluru, Karnataka, India\\nPerforming 1D system level engine thermal management\\nGeneral Motors Technical Center India\\nCFD System Engineer\\nJuly 2015\\xa0-\\xa0February 2019\\xa0(3 years 8 months)\\nBangalore\\nSkills:\\n• Strong technical skills in Amesim, GT power, Matlab.\\n• Underwent training in Star CCM+ and Simulink\\n• Completed both DFSS(Design for Six Sigma) Green belt and Black belt\\ncertification.\\n• Have sufficient knowledge of Pure electric, Hybrid, Fuel cell vehicles. \\nWork experience highlights\\nRegular role-\\n• Completed 6 projects on Camphaser dynamic analysis, 3 projects on\\nLubrication system analysis, 5 \\non Fuel system analysis, 3 on Vane pump modelling using Amesim and\\ndelivered results on time \\nwith First time quality.\\n• Completed 3 projects on Crankcase breathing analysis and 2 on cooling\\nsystem analysis using GT \\npower.\\n• Performed flow vs Pressure drop analysis on complex restrictions in the\\nlubrication system using \\nCCM+.\\nQuality/Efficiency/Design improvement role-\\n• Developed crankcase breathing analysis procedure by visiting test setups in\\nGM tech center at \\nPontiac, collecting data from the suppliers and benchmarking the analysis\\nresults to match the \\n\\xa0 Page 2 of 3\\xa0 \\xa0\\ntest.\\n• Developed cam phaser dynamic analysis procedure by coupling with lube\\ncircuit and accurately \\npredicting the OCV feed pressure and the camphaser response rates.\\n• Automated fuel system analysis procedure by using Matlab scripts and\\ncoupled it with AMESim \\nwhich saved 4 to 5 hours of post processing time.\\n• Provided design modifications to Lubrication system Design Release\\nEngineer(DRE) and matched \\nthe desired pressure at the gallery.\\nInnovative/mentoring role- \\n• Published two defensive publications on the topic –‘Obtaining optimum\\ncamphaser response by \\ndynamically changing the bias spring preload angle’. \\n• Coached and mentored a trainee engineer on Crankcase breathing, Fuel\\nsystem, Lube system and \\nCamphaser analysis procedures using Matlab and GT power.\\nTravel experience\\n• Was sent to GM tech center in Detroit to support Camphaser and Crankcase \\nbreathing analysis procedure improvement work.\\nEducation\\nIndian Institute of Technology, Madras\\nMaster of Technology - MTech,\\xa0fluid\\xa0·\\xa0(2013\\xa0-\\xa02015)\\n\\xa0 Page 3 of 3\\n\\nWith this context, please chat with the user, always staying in character as Chaithanya Ramkumar.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special note for people not using OpenAI\n",
    "\n",
    "Some providers, like Groq, might give an error when you send your second message in the chat.\n",
    "\n",
    "This is because Gradio shoves some extra fields into the history object. OpenAI doesn't mind; but some other models complain.\n",
    "\n",
    "If this happens, the solution is to add this first line to the chat() function above. It cleans up the history variable:\n",
    "\n",
    "```python\n",
    "history = [{\"role\": h[\"role\"], \"content\": h[\"content\"]} for h in history]\n",
    "```\n",
    "\n",
    "You may need to add this in other chat() callback functions in the future, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback _ProactorBasePipeTransport._call_connection_lost(None)\n",
      "handle: <Handle _ProactorBasePipeTransport._call_connection_lost(None)>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sindh\\AppData\\Roaming\\uv\\python\\cpython-3.12.12-windows-x86_64-none\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\sindh\\AppData\\Roaming\\uv\\python\\cpython-3.12.12-windows-x86_64-none\\Lib\\asyncio\\proactor_events.py\", line 165, in _call_connection_lost\n",
      "    self._sock.shutdown(socket.SHUT_RDWR)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "Exception in callback _ProactorBasePipeTransport._call_connection_lost(None)\n",
      "handle: <Handle _ProactorBasePipeTransport._call_connection_lost(None)>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sindh\\AppData\\Roaming\\uv\\python\\cpython-3.12.12-windows-x86_64-none\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\sindh\\AppData\\Roaming\\uv\\python\\cpython-3.12.12-windows-x86_64-none\\Lib\\asyncio\\proactor_events.py\", line 165, in _call_connection_lost\n",
      "    self._sock.shutdown(socket.SHUT_RDWR)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A lot is about to happen...\n",
    "\n",
    "1. Be able to ask an LLM to evaluate an answer\n",
    "2. Be able to rerun if the answer fails evaluation\n",
    "3. Put this together into 1 workflow\n",
    "\n",
    "All without any Agentic framework!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pydantic model for the Evaluation\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"You are an evaluator that decides whether a response to a question is acceptable. \\\n",
    "You are provided with a conversation between a User and an Agent. Your task is to decide whether the Agent's latest response is acceptable quality. \\\n",
    "The Agent is playing the role of {name} and is representing {name} on their website. \\\n",
    "The Agent has been instructed to be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "The Agent has been provided with context on {name} in the form of their summary and LinkedIn details. Here's the information:\"\n",
    "\n",
    "evaluator_system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "evaluator_system_prompt += f\"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += \"Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "gemini = OpenAI(\n",
    "    api_key=os.getenv(\"GOOGLE_API_KEY\"), \n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(reply, message, history) -> Evaluation:\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": evaluator_system_prompt}] + [{\"role\": \"user\", \"content\": evaluator_user_prompt(reply, message, history)}]\n",
    "    response = gemini.beta.chat.completions.parse(model=\"gemini-2.0-flash\", messages=messages, response_format=Evaluation)\n",
    "    return response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": \"do you hold a patent?\"}]\n",
    "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "reply = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(reply, \"do you hold a patent?\", messages[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + \"\\n\\n## Previous answer rejected\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
    "    updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "    messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    if \"patent\" in message:\n",
    "        system = system_prompt + \"\\n\\nEverything in your reply needs to be in pig latin - \\\n",
    "              it is mandatory that you respond only and entirely in pig latin\"\n",
    "    else:\n",
    "        system = system_prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    reply =response.choices[0].message.content\n",
    "\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "    \n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"Passed evaluation - returning reply\")\n",
    "    else:\n",
    "        print(\"Failed evaluation - retrying\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)       \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
